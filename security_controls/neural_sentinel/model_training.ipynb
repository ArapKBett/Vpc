# Neural Sentinel - AI Intrusion Detection Model Training
# Path: /security_controls/neural_sentinel/model_training.ipynb
# Description: Jupyter notebook for training quantum-inspired neural network IDS

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
import matplotlib.pyplot as plt

# Quantum-inspired neural network architecture
class QuantumIDSModel(tf.keras.Model):
    def __init__(self, input_shape):
        super(QuantumIDSModel, self).__init__()
        self.input_layer = layers.InputLayer(input_shape=input_shape)
        
        # Quantum-inspired layers
        self.dense1 = layers.Dense(128, activation='selu')
        self.dropout1 = layers.Dropout(0.3)
        self.dense2 = layers.Dense(64, activation='selu')
        self.attention = layers.MultiHeadAttention(num_heads=4, key_dim=64)
        self.dense3 = layers.Dense(32, activation='selu')
        self.output_layer = layers.Dense(1, activation='sigmoid')
        
    def call(self, inputs):
        x = self.input_layer(inputs)
        x = self.dense1(x)
        x = self.dropout1(x)
        x = self.dense2(x)
        
        # Self-attention mechanism
        attn_output = self.attention(x, x)
        x = layers.Add()([x, attn_output])
        x = layers.LayerNormalization()(x)
        
        x = self.dense3(x)
        return self.output_layer(x)

# Load and preprocess dataset
print("Loading dataset...")
df = pd.read_csv('network_traffic.csv')
X = df.drop(['label', 'timestamp'], axis=1).values
y = df['label'].values

# Split and scale data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize model
model = QuantumIDSModel(input_shape=(X_train.shape[1],))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall'),
        tf.keras.metrics.AUC(name='auc')
    ]
)

# Adversarial training data
def generate_adversarial_samples(X, y, epsilon=0.1):
    X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)
    with tf.GradientTape() as tape:
        tape.watch(X_tensor)
        prediction = model(X_tensor)
        loss = tf.keras.losses.binary_crossentropy(
            tf.ones_like(prediction), prediction)
    gradient = tape.gradient(loss, X_tensor)
    perturbation = epsilon * tf.sign(gradient)
    return X + perturbation.numpy()

X_adv = generate_adversarial_samples(X_train[:1000], y_train[:1000])
X_train_mixed = np.vstack([X_train, X_adv])
y_train_mixed = np.concatenate([y_train, np.ones(len(X_adv))])

# Train model
print("Training model...")
history = model.fit(
    X_train_mixed,
    y_train_mixed,
    epochs=50,
    batch_size=512,
    validation_data=(X_test, y_test),
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)
    ]
)

# Evaluate model
print("Evaluating model...")
results = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {results[1]:.4f}")
print(f"Test Precision: {results[2]:.4f}")
print(f"Test Recall: {results[3]:.4f}")
print(f"Test AUC: {results[4]:.4f}")

# Save model and scaler
model.save('quantum_ai_ids.h5')
joblib.dump(scaler, 'quantum_scaler.pkl')

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()
